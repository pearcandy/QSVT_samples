{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is added by sphinx-gallery\n",
    "# It can be customized to whatever you like\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Fitting using Quantum Signal Processing\n",
    "================================================\n",
    "\n",
    "::: {.meta}\n",
    ":property=\\\"og:description\\\": Learn how to create polynomial\n",
    "approximations to functions using Quantum Signal Processing (QSP).\n",
    ":property=\\\"og:image\\\":\n",
    "<https://pennylane.ai/qml/demonstrations/function_fitting_qsp/cover.png>\n",
    ":::\n",
    "\n",
    "*Author: Jay Soni. Posted: 24 May 2022*\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "\n",
    "This demo is inspired by the paper ['A Grand Unification of Quantum\n",
    "Algorithms'](https://arxiv.org/abs/2105.02859). This paper is centered\n",
    "around the Quantum Singular Value Transform (QSVT) protocol and how it\n",
    "provides a single framework to generalize some of the most famous\n",
    "quantum algorithms like Shor's factoring algorithm, Grover search, and\n",
    "more.\n",
    "\n",
    "The QSVT is a method to apply polynomial transformations to the singular\n",
    "values of *any matrix*. This is powerful because from polynomial\n",
    "transformations we can generate arbitrary function transformations using\n",
    "Taylor approximations. The QSVT protocol is an extension of the more\n",
    "constrained Quantum Signal Processing (QSP) protocol which presents a\n",
    "method for polynomial transformation of matrix entries in a single-qubit\n",
    "unitary operator. The QSVT protocol is sophisticated, but the idea at\n",
    "its core is quite simple. By studying QSP, we get a relatively simpler\n",
    "path to explore this idea at the foundation of QSVT.\n",
    "\n",
    "In this demo, we explore the QSP protocol and how it can be used for\n",
    "curve fitting. We show how you can fit polynomials, as illustrated in\n",
    "the animation below.\n",
    "\n",
    "![](../demonstrations/function_fitting_qsp/trained_poly.gif){.align-center\n",
    "width=\"50.0%\"}\n",
    "\n",
    "This is a powerful tool that will ultimately allow us to approximate any\n",
    "function on the interval $[-1, 1]$ that satisfies certain constraints.\n",
    "Before we can dive into function fitting, let's develop some intuition.\n",
    "Consider the following single-qubit operator parameterized by\n",
    "$a \\in [-1, 1]$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{W}(a) = \\begin{bmatrix} a & i\\sqrt{1 - a^{2}} \\\\ i\\sqrt{1 - a^{2}} & a \\end{bmatrix}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "$\\hat{W}(a)$ is called the *signal rotation operator* (SRO). Using this\n",
    "operator, we can construct another operator which we call *signal\n",
    "processing operator* (SPO),\n",
    "\n",
    "$$\\hat{U}_{sp} = \\hat{R}_{z}(\\phi_{0}) \\prod_{k=1}^{d} \\hat{W}(a) \\hat{R}_{z}(\\phi_{k}).$$\n",
    "\n",
    "The SPO is parameterized by a vector $\\vec{\\phi} \\in \\mathbb{R}^{d+1}$,\n",
    "where $d$ is a free parameter which represents the number of repeated\n",
    "applications of $\\hat{W}(a)$.\n",
    "\n",
    "The SPO $\\hat{U}_{sp}$ alternates between applying the SRO $\\hat{W}(a)$\n",
    "and parameterized rotations around the z-axis. Let's see what happens\n",
    "when we try to compute the expectation value\n",
    "$\\bra{0}\\hat{U}_{sp}\\ket{0}$ for the particular case where $d = 2$ and\n",
    "$\\vec{\\phi} = (0, 0, 0)$ :\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{align*}\n",
    "\\bra{0}\\hat{U}_{sp}\\ket{0} &= \\bra{0} \\ \\hat{R}_{z}(0) \\prod_{k=1}^{2} \\hat{W}(a) \\hat{R}_{z}(0) \\ \\ket{0} \\\\\n",
    "\\bra{0}\\hat{U}_{sp}\\ket{0} &= \\bra{0} \\hat{W}(a)^{2} \\ket{0} \\\\\n",
    "\\end{align*}\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\bra{0}\\hat{U}_{sp}\\ket{0} = \\bra{0} \\begin{bmatrix} a & i\\sqrt{1 - a^{2}} \\\\ i\\sqrt{1 - a^{2}} & a \\end{bmatrix} \\ \\circ \\ \\begin{bmatrix} a & i\\sqrt{1 - a^{2}} \\\\ i\\sqrt{1 - a^{2}} & a \\end{bmatrix} \\ket{0}\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\bra{0}\\hat{U}_{sp}\\ket{0} = \\bra{0} \\begin{bmatrix} 2a^{2} - 1 & 2ai\\sqrt{1 - a^{2}} \\\\ 2ai\\sqrt{1 - a^{2}} & 2a^{2} - 1 \\end{bmatrix} \\ket{0}\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\bra{0}\\hat{U}_{sp}\\ket{0} = 2a^{2} - 1$$\n",
    "\n",
    "Notice that this quantity is a polynomial in $a$. Equivalently, suppose\n",
    "we wanted to create a map $S: a \\to 2a^2 - 1$. This expectation value\n",
    "would give us the means to perform such a mapping. This may seem oddly\n",
    "specific at first, but it turns out that this process can be generalized\n",
    "for generating a mapping $S: a \\to \\text{poly}(a)$. The following\n",
    "theorem shows us how:\n",
    "\n",
    "### Theorem: Quantum Signal Processing\n",
    "\n",
    "Given a vector $\\vec{\\phi} \\in \\mathbb{R}^{d+1}$, there exist complex\n",
    "polynomials $P(a)$ and $Q(a)$ such that the SPO, $\\hat{U}_{sp}$, can be\n",
    "expressed in matrix form as:\n",
    "\n",
    "$$\\hat{U}_{sp} = \\hat{R}_{z}(\\phi_{0}) \\prod_{k=1}^{d} \\hat{W}(a) \\hat{R}_{z}(\\phi_{k}),$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{U}_{sp} = \\begin{bmatrix} P(a) & iQ(a)\\sqrt{1 - a^{2}} \\\\ iQ^{*}(a)\\sqrt{1 - a^{2}} & P^{*}(a) \\end{bmatrix},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $a \\in [-1, 1]$ and the polynomials $P(a)$, $Q(a)$ satisfy the\n",
    "following constraints:\n",
    "\n",
    "-   $deg(P) \\leq d \\ $ and $deg(Q) \\leq d - 1$,\n",
    "-   $P$ has parity $d$ mod 2 and $Q$ has parity, $d - 1$ mod 2\n",
    "-   $|P|^{2} + (1 - a^{2})|Q|^{2} = 1$.\n",
    "\n",
    "The third condition is actually quite restrictive because if we\n",
    "substitute $a = \\pm 1$, we get the result $|P^{2}(\\pm 1)| = 1$. Thus it\n",
    "restricts the polynomial to be pinned to $\\pm 1$ at the end points of\n",
    "the domain, $a = \\pm 1$. This condition can be relaxed to\n",
    "$|P^{2}(a)| \\leq 1$ by expressing the signal processing operator in the\n",
    "Hadamard basis, i.e., $\\bra{+}\\hat{U}_{sp}(\\vec{\\phi};a)\\ket{+}$). This\n",
    "is equivalent to redefining $P(a)$ such that:\n",
    "\n",
    "$$P^{'}(a) = \\text{Re}(P(a)) + i\\text{Re}(Q(a))\\sqrt{1 - a^{2}}$$\n",
    "\n",
    "*This is the convention we follow in this demo.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\\'s Plot some Polynomials\n",
    "============================\n",
    "\n",
    "Now we put this theorem to the test! In this section we construct the\n",
    "SRO $\\hat{W}(a)$, and then use PennyLane to define the SPO. To test the\n",
    "theorem we will randomly generate parameters $\\vec{\\phi}$ and plot the\n",
    "expectation value $\\bra{+}\\hat{U}_{sp}(\\vec{\\phi};a)\\ket{+}$ for\n",
    "$a \\in [-1, 1]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we introduce a function called `rotation_mat(a)`, which will\n",
    "construct the SRO matrix. We can also make a helper function\n",
    "(`generate_many_sro(a_vals)`) which, given an array of possible values\n",
    "for '$a$', will generate an array of $\\hat{W}(a)$ associated with each\n",
    "element. We use Pytorch to construct this array as it will later be used\n",
    "as input when training our function fitting model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now having access to the matrix elements of the SRO, we can leverage\n",
    "PennyLane to define a quantum function that will compute the SPO. Recall\n",
    "we are measuring in the Hadamard basis to relax the third condition of\n",
    "the theorem. We accomplish this by sandwiching the SPO between two\n",
    "Hadamard gates to account for this change of basis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we randomly generate the vector $\\vec{\\phi}$ and plot the\n",
    "expectation value $\\bra{+}\\hat{U}_{sp}\\ket{+}$ as a function of $a$. In\n",
    "this case we choose $d = 5$. We expect to observe the following:\n",
    "\n",
    "-   Since $d$ is odd, we expect all of the polynomials we plot to have\n",
    "    odd symmetry\n",
    "-   Since $d = 5$, we expect none of the polynomials will have terms \\~\n",
    "    $O(a^6)$ or higher\n",
    "-   All of the polynomials are bounded by $\\pm1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../demonstrations/function_fitting_qsp/random_poly.png){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly as predicted, all of these conditions are met!\n",
    "\n",
    "-   All curves have odd symmetry\n",
    "-   Qualitatively, the plots look similar to polynomials of low degree\n",
    "-   Each plot does not exceed $\\pm1$ !\n",
    "\n",
    "Function Fitting with Quantum Signal Processing\n",
    "===============================================\n",
    "\n",
    "Another observation we can make about this theorem is the fact that it\n",
    "holds true in both directions: If we have two polynomials $P(a)$ and\n",
    "$Q(a)$ that satisfy the conditions of the theorem, then there exists a\n",
    "$\\vec{\\phi}$ for which we can construct a signal processing operator\n",
    "which maps $a \\to P(a)$.\n",
    "\n",
    "In this section we try to answer the question:\n",
    "\n",
    "**Can we learn the parameter values of** $\\vec{\\phi}$ **to transform our\n",
    "signal processing operator polynomial to fit a given function?**\n",
    "\n",
    "In order to answer this question, we leverage the power of machine\n",
    "learning. In this demo we assume you are familiar with some concepts\n",
    "from quantum machine learning, for a refresher checkout this [blog post\n",
    "on\n",
    "QML](https://pennylane.ai/blog/2021/10/how-to-start-learning-quantum-machine-learning/).\n",
    "We begin by building a machine learning model using Pytorch. The\n",
    "`__init__()` method handles the random initialization of our parameter\n",
    "vector $\\vec{\\phi}$. The `forward()` method takes an array of signal\n",
    "rotation matrices $\\hat{W}(a)$ for varying $a$, and produces the\n",
    "predicted $y$ values.\n",
    "\n",
    "Next we leverage the PennyLane function\n",
    "[qml.matrix()](https://pennylane.readthedocs.io/en/stable/code/api/pennylane.matrix.html?highlight=qml%20matrix#pennylane.matrix),\n",
    "which accepts our quantum function (it can also accept quantum tapes and\n",
    "QNodes) and returns its unitary matrix representation. We are interested\n",
    "in the real value of the top left entry, this corresponds to $P(a)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a `Model_Runner` class to handle running the\n",
    "optimization, storing the results, and providing plotting functionality:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, lets first attempt to fit a polynomial. We\n",
    "expect this to perform well when the target polynomial also obeys the\n",
    "symmetry and degree constraints that our quantum signal processing\n",
    "polynomial does. To do this, we defined a function `custom_poly(x)`\n",
    "which implements the target polynomial. In this case, we (arbitrarily)\n",
    "choose the target polynomial:\n",
    "\n",
    "$$y = 4x^{5} - 5x^{3} + x$$\n",
    "\n",
    "Lets see how well we can fit this polynomial!\n",
    "\n",
    "> ::: {.note}\n",
    "> ::: {.admonition-title}\n",
    "> Note\n",
    "> :::\n",
    ">\n",
    "> Depending on the initial parameters, training can take anywhere from\n",
    "> 10 - 30 mins\n",
    "> :::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.rst-class}\n",
    "sphx-glr-script-out\n",
    "\n",
    "Out:\n",
    "\n",
    "``` {.sourceCode .none}\n",
    "---- iter: 0, loss: 13.5938 -----\n",
    "---- iter: 1000, loss: 11.8809 -----\n",
    "---- iter: 2000, loss: 10.229 -----\n",
    "---- iter: 3000, loss: 8.6693 -----\n",
    "---- iter: 4000, loss: 7.2557 -----\n",
    "---- iter: 5000, loss: 6.0084 -----\n",
    "---- iter: 6000, loss: 4.9197 -----\n",
    "---- iter: 7000, loss: 3.9801 -----\n",
    "---- iter: 8000, loss: 3.1857 -----\n",
    "---- iter: 9000, loss: 2.5312 -----\n",
    "---- iter: 10000, loss: 2.0045 -----\n",
    "---- iter: 11000, loss: 1.5873 -----\n",
    "---- iter: 12000, loss: 1.2594 -----\n",
    "---- iter: 13000, loss: 1.0021 -----\n",
    "---- iter: 14000, loss: 0.7997 -----\n",
    "---- iter: 15000, loss: 0.6397 -----\n",
    "---- iter: 16000, loss: 0.5127 -----\n",
    "```\n",
    "\n",
    "![](../demonstrations/function_fitting_qsp/trained_poly.png){.align-center\n",
    "width=\"50.0%\"}\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to fit that polynomial quite well! Lets try something more\n",
    "challenging: fitting a non-polynomial function. One thing to keep in\n",
    "mind is the symmetry and bounds constraints on our polynomials. If our\n",
    "target function does not satisfy them as well, then we cannot hope to\n",
    "generate a good polynomial fit, regardless of how long we train for.\n",
    "\n",
    "A good non-polynomial candidate to fit to, that obeys our constraints,\n",
    "is the step function. Let's try it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.rst-class}\n",
    "sphx-glr-script-out\n",
    "\n",
    "Out:\n",
    "\n",
    "``` {.sourceCode .none}\n",
    "---- iter: 0, loss: 33.8345 -----\n",
    "---- iter: 1000, loss: 19.0937 -----\n",
    "---- iter: 2000, loss: 11.6557 -----\n",
    "---- iter: 3000, loss: 8.2853 -----\n",
    "---- iter: 4000, loss: 6.6824 -----\n",
    "---- iter: 5000, loss: 5.8523 -----\n",
    "---- iter: 6000, loss: 5.3855 -----\n",
    "---- iter: 7000, loss: 5.1036 -----\n",
    "---- iter: 8000, loss: 4.9227 -----\n",
    "---- iter: 9000, loss: 4.8004 -----\n",
    "---- iter: 10000, loss: 4.7138 -----\n",
    "---- iter: 11000, loss: 4.6502 -----\n",
    "---- iter: 12000, loss: 4.6018 -----\n",
    "---- iter: 13000, loss: 4.5638 -----\n",
    "---- iter: 14000, loss: 4.5333 -----\n",
    "---- iter: 15000, loss: 4.5082 -----\n",
    "---- iter: 16000, loss: 4.4872 -----\n",
    "---- iter: 17000, loss: 4.4693 -----\n",
    "---- iter: 18000, loss: 4.4537 -----\n",
    "---- iter: 19000, loss: 4.4401 -----\n",
    "---- iter: 20000, loss: 4.4281 -----\n",
    "---- iter: 21000, loss: 4.4174 -----\n",
    "---- iter: 22000, loss: 4.4078 -----\n",
    "---- iter: 23000, loss: 4.3991 -----\n",
    "---- iter: 24000, loss: 4.3912 -----\n",
    "---- iter: 25000, loss: 4.3839 -----\n",
    "```\n",
    "\n",
    "![](../demonstrations/function_fitting_qsp/trained_step.png){.align-center\n",
    "width=\"50.0%\"}\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "==========\n",
    "\n",
    "In this demo, we explored the Quantum Signal Processing theorem, which\n",
    "is a method to perform polynomial transformations on the entries of the\n",
    "SRO $\\hat{W}(a)$. This polynomial transformation arises from the\n",
    "repeated application of $\\hat{W}(a)$ and the parameterized Z-axis\n",
    "rotations $e^{i \\phi \\hat{Z}}$. Note, the SRO is itself a\n",
    "transformation, in this case a rotation around the X-axis by\n",
    "$\\theta = -2 \\cos^{-1}(a)$, which rotates our basis. Thus the underlying\n",
    "principal of quantum signal processing is that we can generate\n",
    "polynomial transformations through parameterized rotations along a\n",
    "principal axis followed by change of basis transformations which\n",
    "re-orients this axis.\n",
    "\n",
    "This is the same principal at the heart of QSVT. In this case the\n",
    "subspace in which we apply our parameterized rotations is defined by the\n",
    "singular vectors, the change of basis transformation takes us between\n",
    "these subspaces and this allows us to apply polynomial transformations\n",
    "on the singular values of our matrix of interest.\n",
    "\n",
    "We also showed that one could use a simple gradient descent model to\n",
    "train a parameter vector $\\vec{\\phi}$ to generate reasonably good\n",
    "polynomial approximations of arbitrary functions (provided the function\n",
    "satisfied the same constraints). This isn\\'t the only way to compute the\n",
    "optimal values. It turns out there exist *efficient* algorithms for\n",
    "explicitly computing the optimal values for $\\vec{\\phi}$ known as\n",
    "\\\"Remez-type exchange algorithms\\\" for analytic function fitting. If you\n",
    "want to explore other approaches to function fitting, checkout this\n",
    "[demo](https://pennylane.ai/qml/demos/quantum_neural_net.html) where we\n",
    "use a photonic neural network for function fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../demonstrations/function_fitting_qsp/trained_step.gif){.align-center\n",
    "width=\"50.0%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "==========\n",
    "\n",
    "\\[1\\]: *John M. Martyn, Zane M. Rossi, Andrew K. Tan, Isaac L. Chuang.\n",
    "\"A Grand Unification of Quantum Algorithms\"* [PRX Quantum 2,\n",
    "040203](https://arxiv.org/abs/2105.02859)*, 2021.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.bio photo=\"../_static/authors/jay_soni.png\"}\n",
    "Jay Soni\n",
    "\n",
    "Jay completed his BSc. in Mathematical Physics from the University of\n",
    "Waterloo and currently works as a Quantum Software Developer at Xanadu.\n",
    "Fun fact, you will often find him sipping on a Tim Horton\\'s IceCapp\n",
    "while he is coding.\n",
    ":::\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
